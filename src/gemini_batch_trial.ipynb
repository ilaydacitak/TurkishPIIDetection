{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6294f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import dotenv\n",
    "import base64\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "import gcp_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0cc2e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e216c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_api_key = os.getenv(\"free_api_key\")\n",
    "billed_api_key = os.getenv(\"billed_api_key\")\n",
    "\n",
    "client = genai.Client(api_key=billed_api_key) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d1cc20",
   "metadata": {},
   "source": [
    "### Gemini Input Prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37991039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output jsonl file name, yani Gemini modeline verilecek input\n",
    "OUTPUT_FILE = \"gemini_batch_input_v0.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "038f1df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "Tell me 3 baby boy names that start with Er\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Tell me 3 baby boy names that start with Er\"\"\"\n",
    "\n",
    "print(\"Prompt:\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7da71520",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create jsonl file\n",
    "\n",
    "n_repeat = 100\n",
    "\n",
    "\n",
    "with open(OUTPUT_FILE, 'a', encoding='utf-8') as f:\n",
    "    for idx in range(n_repeat):\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Step.1 Construct prompt\n",
    "            prompt = f\"\"\"Tell me 3 baby boy names that start with Er\"\"\"\n",
    "            \n",
    "            # Step.2 Create batch request\n",
    "            batch_request = {\n",
    "                    \"key\": f\"{idx}\",\n",
    "                    \"request\": {\n",
    "                        \"contents\": [\n",
    "                            {\n",
    "                                \"parts\": [\n",
    "                                    {\"text\": prompt}\n",
    "                                ]\n",
    "                            }\n",
    "                        ],\n",
    "                    }\n",
    "                }\n",
    "            \n",
    "\n",
    "            # Step.3 Write request to the jsonl file\n",
    "            f.write(json.dumps(batch_request, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "        except:\n",
    "\n",
    "            print(f\"An error occured for\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc6852",
   "metadata": {},
   "source": [
    "### Gemini Start Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d24cb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created batch job: batches/ixfnf86mx2e554pe5uuo2ow8viopkgh7qwlx\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the prepared jsonl file\n",
    "uploaded_jsonl_file = client.files.upload(\n",
    "    file=OUTPUT_FILE,\n",
    "    config=types.UploadFileConfig(display_name='my_PII_first_request_upload', mime_type='jsonl')\n",
    ")\n",
    "\n",
    "# 2. Create batch job\n",
    "file_batch_job = client.batches.create(\n",
    "    model=os.getenv(\"GEMINI_MODEL\"),\n",
    "    src=uploaded_jsonl_file.name,\n",
    "    config={\n",
    "        'display_name': \"my_PII_first_request_job\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(f\"Created batch job: {file_batch_job.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7f44a1",
   "metadata": {},
   "source": [
    "### Get Status of Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7fa32dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Name: batches/ixfnf86mx2e554pe5uuo2ow8viopkgh7qwlx\n",
      "Job Status: JOB_STATE_PENDING\n",
      "Job Creation Time: 2026-01-19 20:39:48.227732+00:00\n",
      "------------------------------\n",
      "Job Name: batches/e04c45jry7riixqyx8fh3lyl1jb0qxng2ez7\n",
      "Job Status: JOB_STATE_SUCCEEDED\n",
      "Job Creation Time: 2026-01-02 01:58:25.600100+00:00\n",
      "------------------------------\n",
      "Job Name: batches/ea2evcbvm6e0o5aqq7gpgc4weujrtnstr08c\n",
      "Job Status: JOB_STATE_SUCCEEDED\n",
      "Job Creation Time: 2025-12-18 21:43:36.393371+00:00\n",
      "------------------------------\n",
      "Job Name: batches/brgbfm8p5pjncw99gnl41qw8ljnoziix5g0w\n",
      "Job Status: JOB_STATE_SUCCEEDED\n",
      "Job Creation Time: 2025-12-18 20:55:01.668785+00:00\n",
      "------------------------------\n",
      "Job Name: batches/xbkd0pyauy1y35i8lcmu98molekqmba7thrr\n",
      "Job Status: JOB_STATE_SUCCEEDED\n",
      "Job Creation Time: 2025-12-18 16:12:47.970228+00:00\n",
      "------------------------------\n",
      "Job Name: batches/6nrn91xkstu16lka7yo5isb4i0l9kznibd83\n",
      "Job Status: JOB_STATE_SUCCEEDED\n",
      "Job Creation Time: 2025-12-18 00:46:50.916629+00:00\n",
      "------------------------------\n",
      "Job Name: batches/fyhfnq6cqge0ga2c7snx4hhzmja6n0hbcnmn\n",
      "Job Status: JOB_STATE_SUCCEEDED\n",
      "Job Creation Time: 2025-12-18 00:07:47.523226+00:00\n",
      "------------------------------\n",
      "Job Name: batches/ckfvgn5o1ylmowyjbnagqv89d9eq9bu0kaga\n",
      "Job Status: JOB_STATE_SUCCEEDED\n",
      "Job Creation Time: 2025-12-17 23:45:49.381989+00:00\n",
      "------------------------------\n",
      "Job Name: batches/y6pcph2bev2stcardeotj9rfl26om04c7ppi\n",
      "Job Status: JOB_STATE_SUCCEEDED\n",
      "Job Creation Time: 2025-12-17 21:56:45.046121+00:00\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "gcp_utils.list_all_batch_jobs(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09519d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_parse_batch_results(client, job_id):\n",
    "    # 1. Retrieve the final status of the batch job\n",
    "    batch_job = client.batches.get(name=job_id)\n",
    "    \n",
    "    if batch_job.state.name != 'JOB_STATE_SUCCEEDED':\n",
    "        print(f\"Batch job is not ready. Current state: {batch_job.state.name}\")\n",
    "        return\n",
    "    \n",
    "    # If batch job was created with a file\n",
    "    elif batch_job.dest and batch_job.dest.file_name:\n",
    "        # Results are in a file\n",
    "        result_file_name = batch_job.dest.file_name\n",
    "        print(f\"Results are in file: {result_file_name}\")\n",
    "\n",
    "        print(\"Downloading result file content...\")\n",
    "        file_content = client.files.download(file=result_file_name)\n",
    "        # Process file_content (bytes) as needed\n",
    "        \n",
    "        return file_content\n",
    "\n",
    "    \n",
    "    else:\n",
    "        print(\"No results found (neither file nor inline).\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f7cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch job is not ready. Current state: JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "result = fetch_and_parse_batch_results(client, \"batches/ixfnf86mx2e554pe5uuo2ow8viopkgh7qwlx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af496982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
